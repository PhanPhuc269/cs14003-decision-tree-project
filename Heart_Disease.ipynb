{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a4ef20",
   "metadata": {},
   "source": [
    "# Import các thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f4fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from graphviz import Source\n",
    "from IPython.display import display, Image\n",
    "import seaborn as sns\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfedfad8",
   "metadata": {},
   "source": [
    "# Heart Desease Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff037677",
   "metadata": {},
   "source": [
    "## 1. Chuẩn bị dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f5407",
   "metadata": {},
   "source": [
    "### 1.1. Train và test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Heart Disease dataset\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "\n",
    "# Extract features and labels\n",
    "features = heart_disease.data.features.values\n",
    "labels = np.ravel(heart_disease.data.targets)\n",
    "\n",
    "# Convert labels to binary: 0 (no disease), 1 (disease)\n",
    "labels_binary = np.where(labels > 0, 1, 0)\n",
    "\n",
    "# Handle missing values\n",
    "data = pd.concat([pd.DataFrame(features, columns=heart_disease.data.features.columns), pd.Series(labels_binary, name='num')], axis=1)\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "features = data.iloc[:, :-1].values\n",
    "labels_binary = data.iloc[:, -1].values\n",
    "\n",
    "# Encode the target variable (though not strictly necessary for binary 0/1)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels_binary)\n",
    "\n",
    "# Define class names for binary classification\n",
    "class_names = ['No Disease', 'Disease']\n",
    "\n",
    "# Define train/test split proportions\n",
    "split_ratios = [(0.4, 0.6), (0.6, 0.4), (0.8, 0.2), (0.9, 0.1)]\n",
    "\n",
    "subsets = []\n",
    "\n",
    "for split_ratio in split_ratios:\n",
    "    feature_train, feature_test, label_train, label_test = train_test_split(\n",
    "        features, labels_encoded, test_size=split_ratio[1], random_state=42, stratify=labels_encoded\n",
    "    )\n",
    "    \n",
    "    subsets.append({\n",
    "        'feature_train': feature_train,\n",
    "        'label_train': label_train,\n",
    "        'feature_test': feature_test,\n",
    "        'label_test': label_test\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6311a",
   "metadata": {},
   "source": [
    "### 1.2. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970fddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the class distribution in the original dataset\n",
    "plt.figure(figsize=(10, 5))\n",
    "bins = np.arange(len(np.unique(labels_encoded)) + 1) - 0.5\n",
    "plt.hist(labels_encoded, bins=bins, color=\"green\", alpha=0.7, edgecolor=\"black\")\n",
    "plt.title(\"Class Distribution in the Original Dataset\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(np.arange(len(class_names)), class_names)\n",
    "plt.show()\n",
    "\n",
    "# Visualize distributions for each train/test split\n",
    "for i in range(len(subsets)):\n",
    "    label_train = subsets[i]['label_train']\n",
    "    label_test = subsets[i]['label_test']\n",
    "\n",
    "    bins = np.arange(len(np.unique(labels_encoded)) + 1) - 0.5\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(label_train, bins=bins, color=\"blue\", alpha=0.7, edgecolor=\"black\", label=\"Training\")\n",
    "    plt.title(f\"Class Distribution for {split_ratios[i][0]}/{split_ratios[i][1]} Split (Training)\")\n",
    "    plt.xlabel(\"Classes\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(np.arange(len(class_names)), class_names)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(label_test, bins=bins, color=\"orange\", alpha=0.7, edgecolor=\"black\", label=\"Testing\")\n",
    "    plt.title(f\"Class Distribution for {split_ratios[i][0]}/{split_ratios[i][1]} Split (Testing)\")\n",
    "    plt.xlabel(\"Classes\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(np.arange(len(class_names)), class_names)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2673ac",
   "metadata": {},
   "source": [
    "## 2. Xây dựng Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901bf64a",
   "metadata": {},
   "source": [
    "### 2.1. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdab222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the Decision Tree model using Entropy (Information Gain)\n",
    "models = []\n",
    "for i, subset in enumerate(subsets):\n",
    "    feature_train = subset['feature_train']\n",
    "    label_train = subset['label_train']\n",
    "    # model = DecisionTreeClassifier(criterion='entropy', random_state=42, max_depth=5, class_weight='balanced')\n",
    "    model = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "    model.fit(feature_train, label_train)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c7206",
   "metadata": {},
   "source": [
    "### 2.2. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f\"Decision tree of the model trained with split ratio {split_ratios[i][0]}/{split_ratios[i][1]}\")\n",
    "    # Export the decision tree to DOT format\n",
    "    dot_data = export_graphviz(\n",
    "        models[i],  # Use the correct model from the list\n",
    "        out_file=None,  # Don't save to file, we will use the source in memory\n",
    "        feature_names=heart_disease.data.features.columns.values,  # Use Heart Disease feature names\n",
    "        class_names=class_names,  # Convert class names to strings\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        special_characters=True,\n",
    "        fontname=\"Arial\"\n",
    "    )\n",
    "    \n",
    "    # Render the DOT file with Graphviz\n",
    "    graph = Source(dot_data)\n",
    "    # Visualize the tree\n",
    "    graph.render(f\"./tree/tree1/tree_{split_ratios[i][0]}_{split_ratios[i][1]}\", \n",
    "                 format='png', \n",
    "                 cleanup=True)\n",
    "    display(Image(f\"./tree/tree1/tree_{split_ratios[i][0]}_{split_ratios[i][1]}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cec7e",
   "metadata": {},
   "source": [
    "## 3. Đánh giá Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d4bbf",
   "metadata": {},
   "source": [
    "### 3.1. Classification report & confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bcd28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model and split, make predictions, generate a report, and confusion matrix\n",
    "for i, subset in enumerate(subsets):\n",
    "    feature_train = subset['feature_train']\n",
    "    label_train = subset['label_train']\n",
    "    feature_test = subset['feature_test']\n",
    "    label_test = subset['label_test']\n",
    "    \n",
    "    # Make predictions\n",
    "    label_pred = models[i].predict(feature_test)\n",
    "    \n",
    "    # Print class distribution in test set\n",
    "    print(f\"Split {split_ratios[i]} Class Distribution in Test Set:\")\n",
    "    print(pd.Series(label_test).value_counts())\n",
    "    \n",
    "    # Generate classification report\n",
    "    print(f\"Classification Report for {split_ratios[i][0]}/{split_ratios[i][1]} Split:\")\n",
    "    print(classification_report(label_test, label_pred, target_names=class_names, zero_division=0))\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(label_test, label_pred)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"Confusion Matrix for {split_ratios[i][0]}/{split_ratios[i][1]} Split\")\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f464e",
   "metadata": {},
   "source": [
    "### 3.2. Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08027697",
   "metadata": {},
   "source": [
    "#### 3.2.1. Tỷ lệ 40/60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45962c3b",
   "metadata": {},
   "source": [
    "- Độ chính xác: 78% trên 179 mẫu kiểm tra.\n",
    "- F1-score trung bình (macro/weighted): khoảng 0.77–0.78.\n",
    "- Lớp “Không bệnh”: F1-score = 0.80, recall = 0.82, mô hình nhận diện khá tốt.\n",
    "- Lớp “Có bệnh”: F1-score = 0.75, recall = 0.72, vẫn còn bỏ sót khoảng 28% số bệnh nhân.\n",
    "- Mô hình thiên nhẹ về lớp “Không bệnh”, nhưng vẫn duy trì hiệu suất tổng thể khá ổn định."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5a27c",
   "metadata": {},
   "source": [
    "#### 3.2.2. Tỷ lệ 60/40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67bbeff",
   "metadata": {},
   "source": [
    "- Độ chính xác: 75% trên 119 mẫu kiểm tra.\n",
    "- Lớp “Không bệnh”: recall cao (0.86), cho thấy mô hình phát hiện tốt các ca không bệnh.\n",
    "- Lớp “Có bệnh”: recall giảm còn 0.62, mô hình bỏ sót nhiều hơn so với tỷ lệ 40/60.\n",
    "- F1-score cả hai lớp đều giảm nhẹ, hiệu suất không được cải thiện rõ dù tăng dữ liệu huấn luyện.\n",
    "- Mô hình có xu hướng thiên về lớp “Không bệnh”, cần điều chỉnh để cân bằng hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5b8328",
   "metadata": {},
   "source": [
    "#### 3.2.3. Tỷ lệ 80/20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1a93f",
   "metadata": {},
   "source": [
    "- Độ chính xác: 77% trên 60 mẫu kiểm tra.\n",
    "- Lớp “Không bệnh”: F1-score = 0.77.\n",
    "- Lớp “Có bệnh”: recall cải thiện rõ rệt lên 0.79 → mô hình phát hiện nhiều bệnh nhân hơn.\n",
    "- Mô hình duy trì được độ chính xác tốt, F1-score hai lớp cân bằng hơn.\n",
    "- Đây là tỷ lệ có hiệu suất ổn định và hiệu quả nhất trong các thử nghiệm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f48a8c",
   "metadata": {},
   "source": [
    "#### 3.2.4. Tỷ lệ 90/10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb954e",
   "metadata": {},
   "source": [
    "- Độ chính xác: 70% trên 30 mẫu kiểm tra – thấp nhất trong 4 tỷ lệ.\n",
    "- Lớp “Không bệnh”: recall = 0.81, precision giảm còn 0.68, dễ nhầm lẫn.\n",
    "- Lớp “Có bệnh”: recall chỉ đạt 0.57, gần một nửa số bệnh nhân không được phát hiện.\n",
    "- F1-score dao động từ 0.64–0.74, cho thấy độ ổn định không cao.\n",
    "- Kích thước test set nhỏ gây nhiễu trong đánh giá, không phản ánh đúng hiệu suất thực tế."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab2d54",
   "metadata": {},
   "source": [
    "## 4. Độ sâu (depth) và độ chính xác (accuracy) của Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057c233",
   "metadata": {},
   "source": [
    "### 4.1 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a833e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 80/20 split (index 2 in split_ratios)\n",
    "subset_80_20 = subsets[2]\n",
    "feature_train_80_20 = subset_80_20['feature_train']\n",
    "label_train_80_20 = subset_80_20['label_train']\n",
    "feature_test_80_20 = subset_80_20['feature_test']\n",
    "label_test_80_20 = subset_80_20['label_test']\n",
    "\n",
    "accuracy_scores = []\n",
    "depths = [None, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "for depth in depths:\n",
    "    model = DecisionTreeClassifier(criterion='entropy', random_state=42, max_depth=depth, class_weight='balanced')\n",
    "    model.fit(feature_train_80_20, label_train_80_20)\n",
    "\n",
    "    print(f\"Decision tree of the model trained with split ratio 80/20 and max depth {depth}\")\n",
    "    # Export the decision tree to DOT format\n",
    "    dot_data = export_graphviz(\n",
    "        model,\n",
    "        out_file=None,\n",
    "        feature_names=heart_disease.data.features.columns,\n",
    "        class_names=class_names,\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        special_characters=True,\n",
    "        fontname=\"Arial\"\n",
    "    )\n",
    "    \n",
    "    # Render the DOT file with Graphviz\n",
    "    graph = Source(dot_data)\n",
    "    # Visualize the tree\n",
    "    graph.render(f\"./tree_80_20/tree1/tree_{depth}\", \n",
    "                 format='png', \n",
    "                 cleanup=True)\n",
    "    display(Image(filename=f\"./tree_80_20/tree1/tree_{depth}.png\"))\n",
    "\n",
    "    # Make predictions and calculate accuracy\n",
    "    pred = model.predict(feature_test_80_20)\n",
    "    accuracy = accuracy_score(label_test_80_20, pred)\n",
    "    print(f\"Accuracy for max_depth {depth}: {accuracy:.4f}\")\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "# Plot the results\n",
    "depths_for_plot = [str(d) if d is not None else 'None' for d in depths]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(depths_for_plot, accuracy_scores, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Accuracy vs Max Depth for Decision Tree (80/20 Split)')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(depths_for_plot)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73239c75",
   "metadata": {},
   "source": [
    "### 4.2. Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7f85d",
   "metadata": {},
   "source": [
    "| max_depth | None  | 2     | 3     | 4     | 5     | 6     | 7     |\n",
    "|-----------|-------|-------|-------|-------|-------|-------|-------|\n",
    "| Accuracy  | 0.774 | 0.730 | 0.797 | 0.775 | 0.778 | 0.771 | 0.773 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3fce2b",
   "metadata": {},
   "source": [
    "- Độ chính xác cao nhất (~79.67%) đạt được khi giới hạn **max_depth = 3**.\n",
    "- Khi **max_depth = None**, độ chính xác giảm nhẹ (~77.4%), có dấu hiệu overfitting nhẹ.\n",
    "- Với **max_depth = 2**, mô hình underfitting rõ rệt (độ chính xác chỉ ~73%).\n",
    "- Từ độ sâu 4–7, hiệu suất dao động nhẹ (77–78%), không cải thiện so với độ sâu 3.\n",
    "- **Kết luận:** Độ sâu = 3 là tối ưu nhất, cân bằng giữa khả năng học và tránh overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
